{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import h5py\n",
        "import xarray_behave as dst\n",
        "# tighter axis limits\n",
        "mpl.rcParams['axes.autolimit_mode'] = 'round_numbers'\n",
        "mpl.rcParams['axes.xmargin'] = 0\n",
        "mpl.rcParams['axes.ymargin'] = 0\n",
        "# sane imshow size\n",
        "mpl.rc('image', interpolation='nearest', aspect='auto', origin='lower')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "assemble all data, returns an xarray (see [xarray docs](http://xarray.pydata.org/en/stable/index.html))\n",
        "\n",
        "\n",
        "Assumes the following folder structure:\n",
        "```\n",
        "root\n",
        " |--datename\n",
        "     |--dat \n",
        "     |    datename_daq.h5\n",
        "     |    datename_timestamps.h5  \n",
        "     |    datename.mp4  \n",
        "     |--res\n",
        "          datename_tracks_fixes.h5  \n",
        "          datename_poses.h5  \n",
        "          datename_song.mat  \n",
        "          datename_songmanual.mat  \n",
        "```    \n",
        "- root: e.g. `/Volumes/ukme04/#Common/chainingmic`\n",
        "- datename: `computername-YYYYMMDD_HHMMSS`, e.g. `localhost-20190401_130742`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "localhost-20181120_144618\n   assembling data\n   saving to localhost-20181120_144618.zarr\n   loading from localhost-20181120_144618.zarr\n<xarray.Dataset>\nDimensions:              (bodyparts: 3, coords: 2, event_types: 12, flies: 2, poseparts: 12, sampletime: 6035114, time: 603512)\nCoordinates:\n  * bodyparts            (bodyparts) <U6 'head' 'center' 'tail'\n  * coords               (coords) <U1 'y' 'x'\n    event_categories     (event_types) <U7 'event' 'event' ... 'segment'\n  * event_types          (event_types) <U19 'song_pulse_any_fss' ... 'vibration_manual'\n    nearest_frame        (time) uint64 622 623 623 623 ... 60931 60931 60931\n  * poseparts            (poseparts) <U16 'head' 'neck' ... 'right_wing' 'tail'\n  * sampletime           (sampletime) float64 0.0 9.99e-05 ... 603.5 603.5\n  * time                 (time) float64 0.0 0.0009997 0.001999 ... 603.5 603.5\nDimensions without coordinates: flies\nData variables:\n    body_positions       (time, flies, bodyparts, coords) float64 840.5 ... 307.2\n    pose_positions       (time, flies, poseparts, coords) float64 -25.55 ... nan\n    pose_positions_allo  (time, flies, poseparts, coords) float64 834.5 ... nan\n    song                 (sampletime) float64 0.007877 0.01642 ... -0.01066\n    song_events          (time, event_types) int16 0 0 0 0 0 0 0 ... 0 0 0 0 0 0\nAttributes:\n    dat_path:                 dat\n    datename:                 localhost-20181120_144618\n    res_path:                 res\n    root:                     \n    target_sampling_rate_Hz:  1000\n    video_filename:           dat/localhost-20181120_144618/localhost-2018112...\n"
        }
      ],
      "source": [
        "datename = 'localhost-20181120_144618'\n",
        "root = '/Volumes/ukme04/#Common/chainingmic'\n",
        "print(datename)\n",
        "print(f'   assembling data')\n",
        "dataset = dst.assemble(datename, dat_path='dat', res_path='res')\n",
        "\n",
        "print(f'   saving to {datename  + \".zarr\"}')\n",
        "dst.save(datename  + '.zarr', dataset)\n",
        "\n",
        "print(f'   loading from {datename  + \".zarr\"}')\n",
        "dataset = dst.load(datename + '.zarr')\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset.song.attrs\n",
        "print(dataset.song_events.attrs['event_times'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While one big advantage of xarrays is fancy/semantic indexing (for instance by time), access to the underlying raw data is also simple:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use attribute-like (dot-notation) or dict-like notation to access individual variables in the data set - this will return DataArrays\n",
        "print('song_labels as xarray (attribute-like access):\\n', dataset.song_labels)\n",
        "print('song_labels as xarray (dict-like access):\\n', dataset['song_labels'])\n",
        "\n",
        "# if you want the underlying raw numpy array, simply append the above by `.data`\n",
        "print('ACCESS RAW DATA:')\n",
        "print('song_labels as numpy array (attribute-like access):', dataset.song_labels.values)\n",
        "print('song_labels as numpy array (dict-like access):', dataset['song_labels'].values)\n",
        "\n",
        "# the same goes for coordinates\n",
        "print('COORDINATE ACCESS:')\n",
        "print('nearest_frame:', dataset.nearest_frame.data)\n",
        "print('time:', dataset['time'].data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can address all the different data types - the raw song recording, the song annotations, and the tracked data using time units without having to worry about the different sampling rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t0 = 75  # seconds\n",
        "t1 = t0+10  # seconds\n",
        "\n",
        "plt.gcf().set_size_inches(30, 10)\n",
        "plt.subplot(311)\n",
        "dataset.song.sel(sampletime=slice(t0, t1)).plot()  # using the .sel syntax with `slice`\n",
        "plt.ylabel('merged microphone signal [V]')\n",
        "\n",
        "plt.subplot(613)\n",
        "dataset.song_labels.loc[t0:t1].plot()  # or directly using .loc[...]\n",
        "plt.yticks([0, 1, 2], labels=['no song','pulse','sine'])\n",
        "\n",
        "plt.subplot(614)\n",
        "ds = dataset.song_events.sel(time=slice(t0, t1))\n",
        "plt.plot(ds.time, ds.values)\n",
        "plt.legend(ds.event_types.values)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.yticks([0, 1], labels=['no event','event'])\n",
        "plt.xlabel('time [seconds]');\n",
        "\n",
        "plt.subplot(313)\n",
        "dataset.body_positions.sel(time=slice(t0, t1), bodyparts='center', coords='x').T.plot(x='time', hue='flies')\n",
        "# equivalent to: `dataset.body_positions.loc[t0:t1, :, 'center', 'x'].T.plot(x='time', hue='flies')`\n",
        "# but the first variant is preferable because it's more explicit\n",
        "plt.xlabel('time [seconds]');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dataset.song_events)\n",
        "plt.plot(dataset.song_events.loc[78:85, 'pulse_manual'])\n",
        "np.where(dataset.song_events.loc[78:85, 'pulse_manual'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "song = dataset.song.sel(sampletime=slice(t0, t1))\n",
        "print(song)\n",
        "ds = dataset.song_events.sel(time=slice(t0, t1))\n",
        "print(ds)\n",
        "indices, types = np.where(ds.values)\n",
        "times = ds.time[indices]\n",
        "\n",
        "waveforms = np.zeros((len(indices), 201))\n",
        "for cnt, tim in enumerate(times):\n",
        "    tmp = song.sel(sampletime=slice(tim-0.01, tim+0.01)).values\n",
        "    waveforms[cnt,: ] = tmp[:1000]\n",
        "\n",
        "plt.gcf().set_size_inches(40, 10)\n",
        "for cnt, typ in enumerate(np.unique(types)):\n",
        "    plt.subplot(2,4, 1+cnt)\n",
        "    plt.imshow(waveforms[types==typ,:], cmap='RdBu_r');\n",
        "    plt.title(ds.event_types[typ].values)\n",
        "    plt.subplot(2,4, 4+1+cnt)\n",
        "    plt.plot(waveforms[types==typ,:].T, linewidth=0.5);\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from videoreader import VideoReader\n",
        "filepath = f'dat/{datename}/{datename}.mp4'\n",
        "vr = VideoReader(filepath)\n",
        "\n",
        "time = 30 #seconds\n",
        "frame_number = dataset.nearest_frame.loc[time]  # get frame number for that idx\n",
        "frame = vr[frame_number]\n",
        "\n",
        "plt.gcf().set_size_inches(30,15)\n",
        "plt.subplot(121)\n",
        "# print(dataset.pose_positions_allo.loc[time, :,:,:])\n",
        "plt.imshow(frame, cmap='Greys')\n",
        "plt.plot(dataset.pose_positions_allo.loc[time, :,:,'y'], dataset.pose_positions_allo.loc[time, :,:,'x'], '.')\n",
        "plt.xlim(0, frame.shape[1])\n",
        "plt.ylim(0, frame.shape[0])\n",
        "plt.title('full frame')\n",
        "\n",
        "plt.subplot(122)\n",
        "fly = 0\n",
        "fly_pos = dataset.pose_positions_allo.loc[time, fly, 'thorax',:].astype(np.uintp)\n",
        "print(fly_pos)\n",
        "box_size = np.uintp(100)\n",
        "x_range = np.clip((fly_pos.loc['x']-box_size, fly_pos.loc['x']+box_size), 0, vr.frame_width-1)\n",
        "y_range = np.clip((fly_pos.loc['y']-box_size, fly_pos.loc['y']+box_size), 0, vr.frame_height-1)\n",
        "plt.imshow(frame[slice(*x_range), slice(*y_range), :], cmap='Greys')\n",
        "plt.title('cropped frame');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.gcf().set_size_inches(10, 10)\n",
        "plt.plot(dataset.pose_positions[::10,0, :,1], dataset.pose_positions[::10,0, :,0], '.', alpha=0.05)\n",
        "\n",
        "plt.xlim(*np.nanpercentile(dataset.pose_positions[...,1], (0.1, 99.9)))\n",
        "plt.ylim(*np.nanpercentile(dataset.pose_positions[...,0], (0.1, 99.9)))\n",
        "\n",
        "leg = plt.legend(dataset.poseparts.values, loc=\"upper left\", bbox_to_anchor=(1,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "times = [100.1, 200.1]\n",
        "frames = dataset.nearest_frame.loc[times]\n",
        "print(f'frames for times {times}:\\n {frames}') # get frame for time\n",
        "idx = [np.where(dataset.nearest_frame==frame)[0][0] for frame in frames]\n",
        "print(f'indices for times {times}:\\n {idx}') # get frame for time\n",
        "\n",
        "frames = [9000, 10000]\n",
        "times = [dataset.time[dataset.nearest_frame==frame][0].values for frame in frames]\n",
        "print(f'times for frames {frames}:\\n {times}') # get frame for time\n",
        "idx = [np.where(dataset.nearest_frame==frame)[0][0] for frame in frames]\n",
        "print(f'times for frames {frames}:\\n {idx}') # get frame for time\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "nteract": {
      "version": "0.22.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}