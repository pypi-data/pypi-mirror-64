{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading ensemble weather forecasts\n",
    "\n",
    "The atmosphere can be viewed as a chaotic system in which the future state depends sensitively on the initial conditions, i.e. a slight change in the initial conditions can lead to a significant change in the forecast outputs. The fact that estimates of the current state are inaccurate and that numerical models have inadequacies, leads to forecast errors and uncertainty that grow with increasing forecast lead time. Ensemble forecasting aims at capturing this forecast uncertainty by generating an ensemble of several possible scenarios with the same probability of occurrence. ([Learn more about ensemble prediction](https://www.youtube.com/watch?v=NLhRUun2iso))\n",
    "\n",
    "In this Notebook we will learn how to download ensemble weather forecasts and hindcasts from the [ECMWF public dataset]. This Notebook downloads 25 (Hindcast: 1981-2016) or 50 (Forecast: 2017-2019) members of the ECMWF seasonal forecast from the server.\n",
    "They are updated and published online every 1st day of the month.\n",
    "\n",
    "The system used to generate the seasonal forecast ensemble is the [SEAS5](https://www.ecmwf.int/en/newsletter/154/meteorology/ecmwfs-new-long-range-forecasting-system-seas5).\n",
    "\n",
    "C3S Seasonal Catalogue: http://apps.ecmwf.int/data-catalogues/c3s-seasonal/?class=c3\n",
    "\n",
    "The files are in netcdf4 format.(https://apps.ecmwf.int/datasets/).\n",
    "\n",
    "<left> <img src=\"../../util/images/uncertainty.1.jpg\" width = \"400px\"><left>\n",
    "## 1. Create an account on the Copernicus Climate Data Store\n",
    "First of all you need to register on the [Copernicus Climate Data Store](https://cds.climate.copernicus.eu)\n",
    "\n",
    "Once you have created an account copy your user ID (UID) and API key. You can find them in your User profile\n",
    "\n",
    "In the folder containing this Notebook you will find a file called \".cdsapirc\". Copy and paste this file in your \"home\" folder. On Windows it corresponds to \"C:/Users/{your username on Windows}/\"\n",
    "\n",
    "Open the copied file with a text editor, you should see this:\n",
    "\n",
    "> url: https://cds.climate.copernicus.eu/api/v2\n",
    "\n",
    "> key: UID:APIkey\n",
    "    \n",
    "Now edit this text and replace UID by your own UID number and APIkey by your own API key number (make sure that both numbers are separated by a colon)\n",
    "    \n",
    "You can also find these intructions in this [link](https://cds.climate.copernicus.eu/api-how-to)\n",
    "\n",
    "## 2. Install the CDS API client library\n",
    "Use this command to install the library:\n",
    "\n",
    "> pip install cdsapi\n",
    "\n",
    "Use [this link](../A%20-%20Knowledge%20transfer/0.b.%20How%20to%20install%20libraries.ipynb) to learn how to install a library.\n",
    "\n",
    "## 3. Import libraries\n",
    "First, we need to import the necessary libraries and tools. **Only if iRONS is run locally**: since one required library, [Netcdf4](https://pypi.org/project/netCDF4/) is not available on Anaconda by default, you must have installed it first. Help on how to install such libraries is given here: [How to install libraries](../A%20-%20Knowledge%20transfer/0.b.%20How%20to%20install%20libraries.ipynb). If iRONS is run on the cloud, e.g. on [Binder](https://mybinder.org/) or [Microsoft Azure Notebooks](https://notebooks.azure.com/), we do not need to install the libraries to import them. \n",
    "Once all the necessary libraries are installed locally or in the case that we are running iRONS on the cloud, we can import them with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cdsapi\n",
    "server = cdsapi.Client()\n",
    "import sys\n",
    "from netCDF4 import Dataset # to extract data from NetCDF files (format of the downloaded ECMWF files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39.0\n"
     ]
    }
   ],
   "source": [
    "import numba\n",
    "print(numba.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tools from the iRONS toolbox**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../Toolbox')\n",
    "from Weather_forecast.Download_forecast import data_retrieval_request\n",
    "from Data_management.Read_data import read_netcdf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the data and file parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originating centre of the ensemble weather forecast\n",
    "originating_centre = 'ECMWF'\n",
    "system = '5'\n",
    "# Weather variables to download\n",
    "weather_variables = ['2m_temperature','evaporation','total_precipitation']\n",
    "# Initial dates of the forecast\n",
    "years = [2014] # np.arange(1981,2019)\n",
    "months = [11] # np.arange(1,13)\n",
    "days = [1]\n",
    "# Forecast leadtime\n",
    "leadtime = 5160 # hours. 5160 hours = 7 months approximately\n",
    "time_step = 24 # hours\n",
    "leadtime_hours = [str(x) for x in np.arange(0,leadtime+time_step,time_step)] \n",
    "# Spatial coordinates\n",
    "grid_resolution = '0.2/0.05' # The first number is east-west resolution (longitude) and the second is north-south (latitude)\n",
    "coordinates = '51.10/-3.5/51.05/-3.3' # This defines a squared area defined by N/W/S/E (in degrees)\n",
    "\n",
    "# Format of the file to download \n",
    "file_format = 'netcdf'\n",
    "# Folder and file name ending\n",
    "folder_path = 'Inputs//'+originating_centre+' forecasts '+file_format\n",
    "file_name_end = '_1d_7m_'+originating_centre+'_Temp_Evap_Rain.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download the forecast file\n",
    "Here we call the submodule to send the request to download the file (the files are stored in the Inputs folder).\n",
    "**Comment**: it may take quite long to download the forecast. As you will see, the request will be queued."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_retrieval_request(originating_centre,system,weather_variables,\n",
    "                           years, months, days, leadtime_hours,\n",
    "                           grid_resolution, coordinates,\n",
    "                           file_format,folder_path,file_name_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save a copy of the forecast file in CSV format\n",
    "The downloaded forecast files are in [NetCDF](https://confluence.ecmwf.int/display/CKB/What+are+NetCDF+files+and+how+can+I+read+them) (Network Common Data Form) format. This file format supports the creation, access, and sharing of array-oriented scientific data.\n",
    "Here we will extract temperature, evaporation and rainfall data using their corresponding short names: 't2m' (temperature), 'e' (evaporation) and 'tp' (rainfall) respectively and save the forecast ensemble for each of these weather variables in CSV (the files are stored in the Inputs folder).  \n",
    "\n",
    "**Comment:** You can find a complete list of weather variables with their corresponding short names in this [link](https://apps.ecmwf.int/codes/grib/param-db/?filter=netcdf).\n",
    "\n",
    "**Comment:** A CSV is a comma-separated values file, which allows data to be saved in a tabular format. CSV files can be used either with most any spreadsheet program, such as Microsoft Excel, or text editors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Extract temperature data (temperature at 2m over the surface: 't2m')\n",
    "Original data is in degK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            file_name = str(year)+str(month).zfill(2)+str(1).zfill(2)+file_name_end\n",
    "            dates_fore,Temp_fore = read_netcdf_data(folder_path,file_name,'t2m')\n",
    "            # Spatially averaged data and converted into degC\n",
    "            Temp_fore_ens = Temp_fore.mean(3).mean(2)-273.15\n",
    "            Temp_fore_df = pd.DataFrame(Temp_fore_ens)\n",
    "            Temp_fore_df.insert(0,'Date',dates_fore.strftime('%d/%m/%Y'))\n",
    "            Temp_fore_df.to_csv('Inputs//'+originating_centre+' forecasts csv'+'//'+\n",
    "                                str(year)+str(month).zfill(2)+str(day).zfill(2)+\n",
    "                                '_1d_7m_'+originating_centre+'_Temp.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaporation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            file_name = str(year)+str(month).zfill(2)+str(1).zfill(2)+file_name_end\n",
    "            dates_fore,Evap_fore = read_netcdf_data(folder_path,file_name,'e')\n",
    "            # Spatially averaged data and coverted into mm\n",
    "            Evap_fore_ens = -Evap_fore.mean(3).mean(2)*1000\n",
    "            Evap_fore_df = pd.DataFrame(Evap_fore_ens)\n",
    "            Evap_fore_df.insert(0,'Date',dates_fore.strftime('%d/%m/%Y'))\n",
    "            Evap_fore_df.to_csv('Inputs//'+originating_centre+' forecasts csv'+'//'+\n",
    "                                str(year)+str(month).zfill(2)+str(day).zfill(2)+\n",
    "                                '_1d_7m_'+originating_centre+'_Evap.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for month in months:\n",
    "        for day in days:\n",
    "            file_name = str(year)+str(month).zfill(2)+str(1).zfill(2)+file_name_end\n",
    "            dates_fore,Rain_fore = read_netcdf_data(folder_path,file_name,'tp')\n",
    "            # Spatially averaged data and coverted into mm\n",
    "            Rain_fore_ens = Rain_fore.mean(3).mean(2)*1000\n",
    "            Rain_fore_df = pd.DataFrame(Rain_fore_ens)\n",
    "            Rain_fore_df.insert(0,'Date',dates_fore.strftime('%d/%m/%Y'))\n",
    "            Rain_fore_df.to_csv('Inputs//'+originating_centre+' forecasts csv'+'//'+\n",
    "                                str(year)+str(month).zfill(2)+str(day).zfill(2)+\n",
    "                                '_1d_7m_'+originating_centre+'_Rain.csv',index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's go to the next Notebook to read and bias correct the downladed data: [Bias correction of weather forecasts](1.b.%20Bias%20correction%20of%20weather%20forecasts.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
