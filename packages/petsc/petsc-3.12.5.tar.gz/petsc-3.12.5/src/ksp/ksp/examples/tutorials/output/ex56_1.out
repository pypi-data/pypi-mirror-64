  0 KSP Residual norm 1279.48 
  1 KSP Residual norm 178.674 
  2 KSP Residual norm 148.871 
  3 KSP Residual norm 49.2774 
  4 KSP Residual norm 40.3056 
  5 KSP Residual norm 9.12121 
  6 KSP Residual norm 4.97858 
  7 KSP Residual norm 1.95325 
  8 KSP Residual norm 1.44373 
  9 KSP Residual norm 0.574068 
 10 KSP Residual norm 0.26276 
 11 KSP Residual norm 0.0580745 
 12 KSP Residual norm 0.0216093 
 13 KSP Residual norm 0.00675462 
Linear solve converged due to CONVERGED_RTOL iterations 13
KSP Object: 8 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 8 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=3 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.01  
        Threshold scaling factor for each level not specified = 1.
        Using aggregates from coarsening process to define subdomains for PCASM
        Using parallel coarse grid solver (all coarse grid equations not put on one process)
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 1
          Number smoothing steps 1
        Complexity:    grid = 1.11819
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 8 MPI processes
      type: cg
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using PRECONDITIONED norm type for convergence test
    PC Object: (mg_coarse_) 8 MPI processes
      type: jacobi
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=60, cols=60, bs=6
        total: nonzeros=3600, allocated nonzeros=3600
        total number of mallocs used during MatSetValues calls=0
          using I-node (on process 0) routines: found 6 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.364032, max = 1.91117
        eigenvalues estimate via cg min 0.0516467, max 1.82016
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_1_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 8 MPI processes
      type: asm
        total subdomain blocks = 10, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_1_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_1_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=30, cols=30
                package used to perform factorization: petsc
                total: nonzeros=900, allocated nonzeros=900
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 6 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=30, cols=30
          total: nonzeros=900, allocated nonzeros=900
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 6 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=474, cols=474, bs=6
        total: nonzeros=64476, allocated nonzeros=64476
        total number of mallocs used during MatSetValues calls=0
          using nonscalable MatPtAP() implementation
          using I-node (on process 0) routines: found 10 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.386231, max = 2.02771
        eigenvalues estimate via cg min 0.0227137, max 1.93116
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_2_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 8 MPI processes
      type: asm
        total subdomain blocks = 79, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_2_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_2_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.05263
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=48, cols=48
                package used to perform factorization: petsc
                total: nonzeros=1440, allocated nonzeros=1440
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 14 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=48, cols=48
          total: nonzeros=1368, allocated nonzeros=1368
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 16 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=8232, cols=8232, bs=3
        total: nonzeros=576000, allocated nonzeros=666792
        total number of mallocs used during MatSetValues calls=0
          has attached near null space
          using I-node (on process 0) routines: found 343 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 8 MPI processes
    type: mpiaij
    rows=8232, cols=8232, bs=3
    total: nonzeros=576000, allocated nonzeros=666792
    total number of mallocs used during MatSetValues calls=0
      has attached near null space
      using I-node (on process 0) routines: found 343 nodes, limit used is 5
  0 KSP Residual norm 0.0127948 
  1 KSP Residual norm 0.00178674 
  2 KSP Residual norm 0.00148871 
  3 KSP Residual norm 0.000492774 
  4 KSP Residual norm 0.000403056 
  5 KSP Residual norm 9.12121e-05 
  6 KSP Residual norm 4.97858e-05 
  7 KSP Residual norm 1.95325e-05 
  8 KSP Residual norm 1.44373e-05 
  9 KSP Residual norm 5.74068e-06 
 10 KSP Residual norm 2.6276e-06 
 11 KSP Residual norm 5.80745e-07 
 12 KSP Residual norm 2.16093e-07 
 13 KSP Residual norm 6.75462e-08 
Linear solve converged due to CONVERGED_RTOL iterations 13
KSP Object: 8 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 8 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=3 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.01  
        Threshold scaling factor for each level not specified = 1.
        Using aggregates from coarsening process to define subdomains for PCASM
        Using parallel coarse grid solver (all coarse grid equations not put on one process)
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 1
          Number smoothing steps 1
        Complexity:    grid = 1.11819
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 8 MPI processes
      type: cg
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using PRECONDITIONED norm type for convergence test
    PC Object: (mg_coarse_) 8 MPI processes
      type: jacobi
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=60, cols=60, bs=6
        total: nonzeros=3600, allocated nonzeros=3600
        total number of mallocs used during MatSetValues calls=0
          using nonscalable MatPtAP() implementation
          using I-node (on process 0) routines: found 6 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.364032, max = 1.91117
        eigenvalues estimate via cg min 0.0516467, max 1.82016
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_1_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 8 MPI processes
      type: asm
        total subdomain blocks = 10, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_1_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_1_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=30, cols=30
                package used to perform factorization: petsc
                total: nonzeros=900, allocated nonzeros=900
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 6 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=30, cols=30
          total: nonzeros=900, allocated nonzeros=900
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 6 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=474, cols=474, bs=6
        total: nonzeros=64476, allocated nonzeros=64476
        total number of mallocs used during MatSetValues calls=0
          using nonscalable MatPtAP() implementation
          using I-node (on process 0) routines: found 10 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.386231, max = 2.02771
        eigenvalues estimate via cg min 0.0227137, max 1.93116
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_2_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 8 MPI processes
      type: asm
        total subdomain blocks = 79, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_2_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_2_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.05263
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=48, cols=48
                package used to perform factorization: petsc
                total: nonzeros=1440, allocated nonzeros=1440
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 14 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=48, cols=48
          total: nonzeros=1368, allocated nonzeros=1368
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 16 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=8232, cols=8232, bs=3
        total: nonzeros=576000, allocated nonzeros=666792
        total number of mallocs used during MatSetValues calls=0
          has attached near null space
          using I-node (on process 0) routines: found 343 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 8 MPI processes
    type: mpiaij
    rows=8232, cols=8232, bs=3
    total: nonzeros=576000, allocated nonzeros=666792
    total number of mallocs used during MatSetValues calls=0
      has attached near null space
      using I-node (on process 0) routines: found 343 nodes, limit used is 5
  0 KSP Residual norm 0.0127948 
  1 KSP Residual norm 0.00178674 
  2 KSP Residual norm 0.00148871 
  3 KSP Residual norm 0.000492774 
  4 KSP Residual norm 0.000403056 
  5 KSP Residual norm 9.12121e-05 
  6 KSP Residual norm 4.97858e-05 
  7 KSP Residual norm 1.95325e-05 
  8 KSP Residual norm 1.44373e-05 
  9 KSP Residual norm 5.74068e-06 
 10 KSP Residual norm 2.6276e-06 
 11 KSP Residual norm 5.80745e-07 
 12 KSP Residual norm 2.16093e-07 
 13 KSP Residual norm 6.75462e-08 
Linear solve converged due to CONVERGED_RTOL iterations 13
KSP Object: 8 MPI processes
  type: cg
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 8 MPI processes
  type: gamg
    type is MULTIPLICATIVE, levels=3 cycles=v
      Cycles per PCApply=1
      Using externally compute Galerkin coarse grid matrices
      GAMG specific options
        Threshold for dropping small values in graph on each level =   -0.01  
        Threshold scaling factor for each level not specified = 1.
        Using aggregates from coarsening process to define subdomains for PCASM
        Using parallel coarse grid solver (all coarse grid equations not put on one process)
        AGG specific options
          Symmetric graph false
          Number of levels to square graph 1
          Number smoothing steps 1
        Complexity:    grid = 1.11819
  Coarse grid solver -- level -------------------------------
    KSP Object: (mg_coarse_) 8 MPI processes
      type: cg
      maximum iterations=10000, initial guess is zero
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using PRECONDITIONED norm type for convergence test
    PC Object: (mg_coarse_) 8 MPI processes
      type: jacobi
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=60, cols=60, bs=6
        total: nonzeros=3600, allocated nonzeros=3600
        total number of mallocs used during MatSetValues calls=0
          using nonscalable MatPtAP() implementation
          using I-node (on process 0) routines: found 6 nodes, limit used is 5
  Down solver (pre-smoother) on level 1 -------------------------------
    KSP Object: (mg_levels_1_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.364032, max = 1.91117
        eigenvalues estimate via cg min 0.0516467, max 1.82016
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_1_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_1_) 8 MPI processes
      type: asm
        total subdomain blocks = 10, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_1_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_1_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=30, cols=30
                package used to perform factorization: petsc
                total: nonzeros=900, allocated nonzeros=900
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 6 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=30, cols=30
          total: nonzeros=900, allocated nonzeros=900
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 6 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=474, cols=474, bs=6
        total: nonzeros=64476, allocated nonzeros=64476
        total number of mallocs used during MatSetValues calls=0
          using nonscalable MatPtAP() implementation
          using I-node (on process 0) routines: found 10 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  Down solver (pre-smoother) on level 2 -------------------------------
    KSP Object: (mg_levels_2_) 8 MPI processes
      type: chebyshev
        eigenvalue estimates used:  min = 0.386231, max = 2.02771
        eigenvalues estimate via cg min 0.0227137, max 1.93116
        eigenvalues estimated using cg with translations  [0. 0.2; 0. 1.05]
        KSP Object: (mg_levels_2_esteig_) 8 MPI processes
          type: cg
          maximum iterations=10, initial guess is zero
          tolerances:  relative=1e-12, absolute=1e-50, divergence=10000.
          left preconditioning
          using PRECONDITIONED norm type for convergence test
        estimating eigenvalues using noisy right hand side
      maximum iterations=1, nonzero initial guess
      tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
      left preconditioning
      using NONE norm type for convergence test
    PC Object: (mg_levels_2_) 8 MPI processes
      type: asm
        total subdomain blocks = 79, amount of overlap = 0
        restriction/interpolation type - BASIC
        Local solve is same for all blocks, in the following KSP and PC objects:
      KSP Object: (mg_levels_2_sub_) 1 MPI processes
        type: preonly
        maximum iterations=10000, initial guess is zero
        tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
        left preconditioning
        using NONE norm type for convergence test
      PC Object: (mg_levels_2_sub_) 1 MPI processes
        type: lu
          out-of-place factorization
          tolerance for zero pivot 2.22045e-14
          matrix ordering: nd
          factor fill ratio given 5., needed 1.05263
            Factored matrix follows:
              Mat Object: 1 MPI processes
                type: seqaij
                rows=48, cols=48
                package used to perform factorization: petsc
                total: nonzeros=1440, allocated nonzeros=1440
                total number of mallocs used during MatSetValues calls=0
                  using I-node routines: found 14 nodes, limit used is 5
        linear system matrix = precond matrix:
        Mat Object: 1 MPI processes
          type: seqaij
          rows=48, cols=48
          total: nonzeros=1368, allocated nonzeros=1368
          total number of mallocs used during MatSetValues calls=0
            using I-node routines: found 16 nodes, limit used is 5
      linear system matrix = precond matrix:
      Mat Object: 8 MPI processes
        type: mpiaij
        rows=8232, cols=8232, bs=3
        total: nonzeros=576000, allocated nonzeros=666792
        total number of mallocs used during MatSetValues calls=0
          has attached near null space
          using I-node (on process 0) routines: found 343 nodes, limit used is 5
  Up solver (post-smoother) same as down solver (pre-smoother)
  linear system matrix = precond matrix:
  Mat Object: 8 MPI processes
    type: mpiaij
    rows=8232, cols=8232, bs=3
    total: nonzeros=576000, allocated nonzeros=666792
    total number of mallocs used during MatSetValues calls=0
      has attached near null space
      using I-node (on process 0) routines: found 343 nodes, limit used is 5
[0]main |b-Ax|/|b|=1.936335e-04, |b|=4.631005e+00, emax=9.968135e-01
