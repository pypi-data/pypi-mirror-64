{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we explore some different options to upload annotations in Remo. We will:\n",
    "\n",
    "- add annotations from a file in a format supported by remo\n",
    "- add annotations from code, which enables uploading annotations from any input format\n",
    "- introduce the concept of Annotation Sets, for finer control over annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by creating a dataset and populating it with some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    (\\(\\ \n",
      "    (>':') Remo server is running: v0.3.10-77-g3ab8aa16\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# need to specify path to remo in notebook\n",
    "local_path_to_repo =  '/home/andrea/Desktop/Projects/repo/remo-python'\n",
    "sys.path.insert(0, local_path_to_repo)\n",
    "\n",
    "import remo\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "urls = ['https://remo-scripts.s3-eu-west-1.amazonaws.com/open_images_sample_dataset.zip']\n",
    "my_dataset = remo.create_dataset(name = 'D1', urls = urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations stored in a file supported by remo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding annotations from a file supported by Remo just requires passing the file via `dataset.add_data` method and specifying the task.**\n",
    "\n",
    "Remo is able to automatically parse annotations in JSON, CSV, XML in a variety of formats (such as Pascal, CoCo, Open Images, etc). You can read more about file formats supported by remo in [our documentation](https://remo.ai/docs/annotation-formats/).\n",
    "\n",
    "**As an example, let's see how to add some annotations for an Object Detection task from a CSV file with encoded classes**\n",
    "\n",
    "In this case, annotations are stored in a CSV file in a format already supported by Remo. Class labels were encoded using [GoogleKnowledgeGraph](https://developers.google.com/knowledge-graph). Remo automatically detects the class encoding and translates it into the corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ImageID', 'Source', 'LabelName', 'Confidence', 'XMin', 'XMax', 'YMin',\n",
       "       'YMax', 'IsOccluded', 'IsTruncated', 'IsGroupOf', 'IsDepiction',\n",
       "       'IsInside'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_files=[os.getcwd() + '/assets/open_sample.csv']\n",
    "\n",
    "df = pd.read_csv(annotation_files[0])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'files_link_result': {'files uploaded': 0, 'annotations': 9, 'errors': []}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.add_data(local_files=annotation_files, annotation_task = 'Object detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see annotation statistics, explore the dataset and further leverage Remo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'AnnotationSet ID': 19,\n",
       "  'AnnotationSet name': 'Object detection',\n",
       "  'n_images': 9,\n",
       "  'n_classes': 15,\n",
       "  'n_objects': 84,\n",
       "  'top_3_classes': [{'name': 'Fruit', 'count': 27},\n",
       "   {'name': 'Sports equipment', 'count': 12},\n",
       "   {'name': 'Mammal', 'count': 7}],\n",
       "  'creation_date': None,\n",
       "  'last_modified_date': '2020-03-15T20:38:00.140964Z'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.get_annotation_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/datasets/11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_901a61a5-01ea-4f4b-9794-110cb25c5f0f\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/datasets/11?allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_901a61a5-01ea-4f4b-9794-110cb25c5f0f\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/dataset_added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add annotations from code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case your annotations are in a custom format, it's still very easy to upload annotations from code (as long as the task is one of those currently supported by Remo).\n",
    "\n",
    "**As an example, let's see how we can add annotations to a specific image from code using the `Annotation` object and `dataset.add_annotations()`**\n",
    "\n",
    "This can be useful for instance to add model predictions as annotations or to tag specific images. \n",
    "In case your input data is in a custom file, you can write a parser to load annotations using the Annotation object.\n",
    "\n",
    "First, let's retrieve one image. The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 1527 - 000a1249af2bc5f0.jpg\n",
      "Resoultion:  1024 x 678\n"
     ]
    }
   ],
   "source": [
    "images = my_dataset.images()\n",
    "my_image = images[1]\n",
    "print(my_image)\n",
    "print('Resoultion: ', my_image.width, 'x', my_image.height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can easily add annotations using `add_annotations()` method of the dataset class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100% - 1/1 - elapsed 0:00:01.001000 - speed: 1.00 img / s, ETA: 0:00:00\n"
     ]
    }
   ],
   "source": [
    "annotations = []\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Human hand'\n",
    "annotation.bbox=[227, 284, 678, 674]\n",
    "annotations.append(annotation)\n",
    "\n",
    "annotation = remo.Annotation()\n",
    "annotation.img_filename = my_image.name\n",
    "annotation.classes='Fashion accessory'\n",
    "annotation.bbox=[496, 322, 544,370]\n",
    "annotations.append(annotation)\n",
    "\n",
    "my_dataset.add_annotations(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open http://localhost:8123/image/1527?dataset_id=18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            id=\"remo_frame_88efd8a5-4f2d-47dd-8289-f3a2877005e4\"\n",
       "            width=\"100%\"\n",
       "            height=\"100px\"\n",
       "            src=\"http://localhost:8123/image/1527?dataset_id=18&allheadless\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        <script type=\"text/javascript\">\n",
       "            (function () {\n",
       "                const iframe = document.getElementById(\"remo_frame_88efd8a5-4f2d-47dd-8289-f3a2877005e4\");\n",
       "                let timeout, delay = 100;\n",
       "            \n",
       "                const setHeight = () => {\n",
       "                  const width = iframe.clientWidth;\n",
       "                  iframe.style.height = (width * screen.height / screen.width) * 0.8 + 'px';\n",
       "                }\n",
       "                window.addEventListener(\"resize\", () => {\n",
       "                    clearTimeout(timeout);\n",
       "                  // start timing for event \"completion\"\n",
       "                  timeout = setTimeout(setHeight, delay);\n",
       "                });\n",
       "                setHeight();\n",
       "            })()\n",
       "        </script>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.view_image(my_image.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_added_annotation.jpeg](assets/added_annotation.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------ THIS SECTION IS WORK IN PROGRESS ------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Behind the scenes, Remo organises annotations in Annotation sets. An annotation set is simply a collection of all the annotations of Dataset.**\n",
    "\n",
    "An annotation set is characterized by a task (such as 'Object Detection') and a list of classes, besides of course the actual annotations.\n",
    "\n",
    "The advantage of grouping annotations in an Annotation Set is that it allows for high-level group operations on all the annotations, such as:\n",
    "- grouping classes together\n",
    "- deleting objects of specific classes\n",
    "- comparing of different annotations (such as ground truth vs prediction, or annotations coming from different annotators)\n",
    "\n",
    "In the examples we have seen before, Remo automatically creates an annotation set and sets it as default. For more control, it's however possible to explicit manipulate Annotation sets objects.\n",
    "\n",
    "\n",
    "**Let's first create an empty annotation set with a predetermined list of classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['Airplane', 'Clothing', 'Dog', 'Fashion accessory', 'Food', 'Footwear', 'Fruit', 'Human arm', \n",
    "         'Human body', 'Human hand', 'Human leg', 'Mammal', 'Man', 'Person', 'Salad', 'Sports equipment', 'Trousers', 'Woman']\n",
    "\n",
    "annotation_set = my_dataset.create_annotation_set(annotation_task = 'Object detection',\n",
    "                                          name = 'Objects',\n",
    "                                          classes = my_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily retrieve different annotation sets of a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Annotation set 15 - 'Object detection', task: Object detection, #classes: 15,\n",
       " Annotation set 16 - 'my_ann_set_2', task: Object detection, #classes: 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_dataset.annotation_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding the file to an existing annotation set, remo automatically only adds annotations for classes that are part of that annotation set. It's possible to add classes to an annotation set, but we require this to be done explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
