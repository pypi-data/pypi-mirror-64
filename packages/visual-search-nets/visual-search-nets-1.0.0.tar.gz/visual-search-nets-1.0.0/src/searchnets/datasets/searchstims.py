"""PyTorch Dataset class for visual search stimuli"""
from pathlib import Path

import imageio
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset


class Searchstims(Dataset):
    """dataset of visual search stimuli"""

    def __init__(self, csv_file, split, transform=None, return_set_size=False):
        """

        Parameters
        ----------
        csv_file : str
            name of .csv file generated by searchnets.data.split
        split : str
            Split of entire dataset to use. One of {'train', 'val', 'test'}.
        transform : callable
            transform to be applied to a single sample from the dataset
        return_set_size : bool
            if True, return visual search stimulus set size for each sample,
            which is the total number of items (targets + distractors) in the image.
            Default is False. Used for calculating accuracy per set size.
        """
        if split not in {'train', 'val', 'test'}:
            raise ValueError("split must be one of: {'train', 'val', 'test'}")

        self.csv_file = csv_file
        self.transform = transform
        self.split = split
        df = pd.read_csv(csv_file)
        df = df[df['split'] == split]
        self.df = df

        img_files = df['img_file'].values
        root_output_dir = df['root_output_dir'].values
        self.x = np.asarray(
            [str(Path(root).joinpath(img_file))
             for root, img_file in zip(root_output_dir, img_files)]
        )

        targ_cond = df['target_condition'].values
        targ_cond = np.asarray(
            [1 if tc == 'present' else 0 for tc in targ_cond]
        )
        self.y = targ_cond

        self.transform = transform

        self.return_set_size = return_set_size
        if return_set_size:
            self.set_size = df['set_size'].values

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        x = imageio.imread(self.x[idx])
        y = self.y[idx]

        if self.transform:
            x = self.transform(x)

        y = torch.from_numpy(np.asarray(y))

        if self.return_set_size:
            set_size = self.set_size[idx]
            sample = (x, y, set_size)
        else:
            sample = (x, y)

        return sample
